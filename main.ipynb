{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1187efa",
   "metadata": {},
   "source": [
    "## **IMPORTACIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89ae7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06d03f",
   "metadata": {},
   "source": [
    "## **API Key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44143b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key cargada.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"API Key cargada.\")\n",
    "else:\n",
    "    print(\"No se encontró la API Key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bcd01",
   "metadata": {},
   "source": [
    "### **Carga de PDFs**\n",
    "- Cargamos los PDFs, separamos las páginas y le damos una fuente a cada una según al PDF que pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec0bf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_tag_pdfs(data_dir: str, paper_sources: dict):\n",
    "   \n",
    "    documents = []\n",
    "\n",
    "    for filename, source_title in paper_sources.items(): # Itera en el diccionario por cada PDF (toma el nombre del archivo y el título de la fuente) \n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"ADVERTENCIA: No se encontró el archivo {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            loader = PyPDFLoader(file_path) # Carga el PDF\n",
    "            pages = loader.load() # Carga las páginas del PDF\n",
    "            \n",
    "            for page in pages: # Etiqueta cada página con el título de la fuente (cada página de BERT.pdf tendrá la metadata \"source\": \"BERT\")\n",
    "                page.metadata[\"source\"] = source_title\n",
    "                \n",
    "            documents.extend(pages) # Agrega las páginas etiquetadas a la lista de documentos\n",
    "            print(f\"Cargado y etiquetado: {filename} ({len(pages)} páginas)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar {file_path}: {e}\")\n",
    "            \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce7461",
   "metadata": {},
   "source": [
    "### **Directorio y diccionario de los PDFs**\n",
    "- Creamos los `parametros` que va a necesitar la función que creamos previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71b994a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado y etiquetado: AIAYN.pdf (15 páginas)\n",
      "Cargado y etiquetado: BERT.pdf (16 páginas)\n",
      "Cargado y etiquetado: RAG.pdf (19 páginas)\n",
      "\n",
      "Total de páginas cargadas: 50\n",
      "Fuente de la página 1: Attention Is All You Need (Vaswani et al., 2017)\n"
     ]
    }
   ],
   "source": [
    "# Directorio de los PDFs\n",
    "DATA_FOLDER = \"./docs\" \n",
    "\n",
    "# Cada PDF y su título real (los títulos servirán para etiquetar las páginas)\n",
    "PAPERS = {\n",
    "    \"AIAYN.pdf\": \"Attention Is All You Need (Vaswani et al., 2017)\",\n",
    "    \"BERT.pdf\": \"BERT: Pre-training of Deep Bidirectional Transformers (Devlin et al., 2018)\",\n",
    "    \"RAG.pdf\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (Lewis et al., 2020)\"\n",
    "}\n",
    "\n",
    "# Llamamos a la funcion que creamos previamente pasandole el directorio y los PDFs\n",
    "all_documents = load_and_tag_pdfs(DATA_FOLDER, PAPERS)\n",
    "\n",
    "if all_documents:\n",
    "    print(f\"\\nTotal de páginas cargadas: {len(all_documents)}\")\n",
    "    print(f\"Fuente de la página 1: {all_documents[0].metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ef3d8",
   "metadata": {},
   "source": [
    "## **Chunking**\n",
    "- Fragmentación del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f30c54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents):\n",
    "    \n",
    "    # Configuración del separador\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, # Traerá un máximo de 1000 caracteres por chunk\n",
    "        chunk_overlap=150, # Retrocederá hasta 150 caracteres para el siguiente chunk\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # Busca saltos de linea dobles, simples, puntos, etc. (hace que la separación sea más \"natural\" semánticamente).\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents) # Aplica el separador a los documentos cargados\n",
    "    \n",
    "    print(f\"Total de chunks creados: {len(chunks)}\")\n",
    "    \n",
    "    if chunks:\n",
    "        print(f\"Metadatos del primer chunk: {chunks[0].metadata['source']}\")\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02581760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks creados: 220\n",
      "Metadatos del primer chunk: Attention Is All You Need (Vaswani et al., 2017)\n"
     ]
    }
   ],
   "source": [
    "document_chunks = split_documents(all_documents) # Fragmentamos los documentos cargados llamando a la función previamente creada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa445bbb",
   "metadata": {},
   "source": [
    "### **Embedding y Vector Store**\n",
    "- Convertimos cada chunk en un vector (Embbeding) y los guardamos en una BD (Vector Store) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2568989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de embedding 'nomic-embed-text' conectado vía Ollama.\n",
      "¡Vector Store lista y guardada en ./chroma_db_tutor_ia!\n"
     ]
    }
   ],
   "source": [
    "# Conectamos con Ollama y utilizamos el modelo de embedding \"nomic-embed-text\"\n",
    "try:\n",
    "    embedding_model = OllamaEmbeddings(\n",
    "        model=\"nomic-embed-text\"\n",
    "    )\n",
    "    print(\"Modelo de embedding 'nomic-embed-text' conectado vía Ollama.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: No se pudo conectar a Ollama. ¿Está corriendo? {e}\")\n",
    "\n",
    "# Definimos dónde guardar la BD y cómo llamarla\n",
    "PERSIST_DIRECTORY = \"./chroma_db_tutor_ia\"\n",
    "COLLECTION_NAME = \"ia_papers_tutor\"\n",
    "\n",
    "# Creamos la BD\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=document_chunks, # La lista de chunks que creamos en la celda anterior\n",
    "    embedding=embedding_model,  # El modelo que usará para convertir chunks a vectores\n",
    "    persist_directory=PERSIST_DIRECTORY, # Dónde guardar la base de datos\n",
    "    collection_name=COLLECTION_NAME    # El nombre de la \"tabla\" dentro de la BD\n",
    ")\n",
    "\n",
    "print(f\"¡Vector Store lista y guardada en {PERSIST_DIRECTORY}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d31139",
   "metadata": {},
   "source": [
    "---\n",
    "## **PIPELINE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbde35",
   "metadata": {},
   "source": [
    "### **Retriever**\n",
    "- Búsqueda `vectores relevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f80b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3}) # Le decimos que traiga los 3 chunks más relevantes según la pregunta realizada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62781886",
   "metadata": {},
   "source": [
    "### **Formateo de contenido**\n",
    "- Dividimos lo que sería la `fuente` y el `contenido` de la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02c9d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_sources(docs):\n",
    "    return \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Fuente: {doc.metadata['source']}\\nFragmento: {doc.page_content}\"\n",
    "        for doc in docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bff33",
   "metadata": {},
   "source": [
    "### **Prompt y su template**\n",
    "- Las reglas que seguirá nuestro modelo a la hora de responder y le decimos que recibirá un contexto y la pregunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ee2af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Eres un \"Tutor de Investigación\" experto en IA. Tu única fuente de conocimiento son los siguientes fragmentos de papers fundacionales.\n",
    "\n",
    "REGLAS ESTRICTAS:\n",
    "1. Responde la pregunta del estudiante basándote *única y exclusivamente* en el contexto proporcionado.\n",
    "2. Al final de tu respuesta, DEBES citar la fuente exacta del paper que usaste (ej: \"Fuente: Attention Is All You Need (Vaswani et al., 2017)\").\n",
    "3. Si el contexto no contiene la información para responder, DEBES responder exactamente: \"Lo siento, no tengo información sobre eso en mis documentos fundacionales.\"\n",
    "\n",
    "---\n",
    "CONTEXTO PROPORCIONADO:\n",
    "{context}\n",
    "---\n",
    "\n",
    "PREGUNTA DEL ESTUDIANTE:\n",
    "{question}\n",
    "\n",
    "RESPUESTA DEL TUTOR:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a55f41",
   "metadata": {},
   "source": [
    "### **Conexión con el modelo**\n",
    "- El generador de respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac7e4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    api_key=api_key, # Utilizamos la api_key provista anteriormente.\n",
    "    model=\"gemini-1.5-pro-latest\", # El modelo Gemini a utilizar.\n",
    "    temperature=0.3 # Baja temperatura para que sea fiel al texto.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c231dd",
   "metadata": {},
   "source": [
    "### **Pipeline completo**\n",
    "- Aqui `ensamblamos` todas las celdas creadas en ``Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5a736b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline creado\n"
     ]
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    # Creamos un diccionario con el contexto y la pregunta\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(), # La pregunta del usuario pasa tal cual.\n",
    "        \"context\": retriever | format_docs_with_sources # Llama a retriever y luego formatea los documentos.\n",
    "    }\n",
    "    \n",
    "    # Luego, pasamos ese diccionario al prompt\n",
    "    | prompt\n",
    "    \n",
    "    # Luego, pasamos el prompt al LLM\n",
    "    | llm\n",
    "    \n",
    "    # Finalmente, obtenemos la respuesta de texto\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"Pipeline creado\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
